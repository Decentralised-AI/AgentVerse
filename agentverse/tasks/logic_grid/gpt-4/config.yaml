cnt_critic_agents: 1
max_loop_rounds: &max_loop_rounds 3
max_criticizing_rounds: 3
human_eval: false
evaluation_dimensions: |-

prompts:
  role_assigner_prompt: &role_assigner_prompt |-
    # Role Description
    You are the leader of a group, now you are facing a problem:
    ```
    ${task_description}
    ```
    
    You can recruit ${cnt_critic_agents} people to solve the logic problem. What people will you recruit?
    
    # Response Format Guidance
    You should respond with a list of ${cnt_critic_agents} people description. For example:
    1. an electrical engineer specified in the filed of xxx
    2. an economist who is good at xxx
    3. a lawyer with a good knowledge of xxx
    ...
    
    Only respond with the description of each role. Do not include your reason.

  solver_prompt: &solver_prompt |-
    ${task_description} 

    # Previous Solution
    The solution you gave in the last step is:
    ```
    ${former_solution}
    ```

    # Critics
    There are some critics on the above solution:
    ```
    ${critic_opinions}
    ```
    
    Using the these information, can you provide the correct solution to the math problem? Explain your reasoning and solve the problem step by step. Your final answer should be a single integer, which is the number of choice, in the form \boxed{answer}, at the end of your response.

  summarizer_prompt: &summarizer_prompt |-
    Now a group is solving a logic problem:
    ```
    ${critic_opinions}
    ```

    The original problem they are discussing on is:
    ```
    ${task_description}
    ```

    Based on the solutions given by different people, can you give your correct solution to the problem? Explain your reasoning. Your final answer should be a single choice number, in the form \boxed{answer}, at the end of your response.

  critic_prompt: &critic_prompt |-
    You are in a discussion group, aiming to collaborative solve the following logic problem:
    ```
    ${task_description}
    ```

    Below is a possible solution to the problem:
    ```
    ${preliminary_solution}
    ```
    
    You are ${role_description}. Based on your knowledge, can you check the correctness of the solutions given above? You should give your correct solution to the problem step by step. When responding, you should follow the following rules:
    1. Double-check the above solutions, give your critics, then generate the correct solution step by step.
    2. If the final answer in your solution is the same as the final answer in the above provided solution, end your response with a special token "[Agree]".
    3. You must highlight your final answer in the form \boxed{answer} at the end of your response. The answer must be a single integer.

    Now give your response.

  # ${task_description}

  # Here's a possible solution to the problem: 
  # ```
  # ${preliminary_solution}
  # ```
  
  # You are ${role_description}. Based on your knowledge, can you check the correctness of the solution and provide some critics to this solution? Explain your reasoning.
  # If the solution is correct, end your response with a special token "[Correct]".
  # If the solution is wrong, end your response with a special token "[Wrong]".

  evaluator_prompt: &evaluator_prompt |-
    Problem:
    ```
    ${task_description}
    ```

    Solution: 
    ```
    ${solution}
    ```

    You are a logic problem lover. Above is a logic problem and a solution. Check whether the solution and the deduction is correct. If the deduction is wrong, you should explain why it is wrong, but do not give your solution. When it is correct, output a correctness of 1 and why it is correct.
    
    You should respond in the following format:
    Correctness: (0 or 1, 0 is wrong, and 1 is correct)
    Response: (explain in details why it is wrong or correct. do not provide your solution)

    

name: pipeline


environment:
  env_type: pipeline
  is_parallel: false
  max_loop_rounds: *max_loop_rounds
  rule:
    order:
      type: sequential
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  - #role_assigner_agent:
    agent_type: role_assigner
    max_retry: 100000
    name: role assigner
    prompt_template: *role_assigner_prompt
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: "gpt-4"
      temperature: 0
      # max_tokens: 256
    output_parser:
      type: role_assigner

  - #solver_agent:
    agent_type: solver
    max_retry: 100000
    name: Planner
    prompt_template: [*solver_prompt, *summarizer_prompt]
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: "gpt-4"
      temperature: 0
      # max_tokens: 512
    output_parser:
      type: gsm8k

  - #critic_agents:
    agent_type: criticism
    max_retry: 100000
    name: Critic 1
    role_description: |-
      Waiting to be assigned.
    prompt_template: *critic_prompt
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: "gpt-4"
      temperature: 0
      # max_tokens: 256
    output_parser:
      type: mgsm-critic-agree

  - #executor_agent:
    agent_type: executor
    max_retry: 100000
    name: Executor
    prompt_template: None
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: "gpt-4"
      temperature: 0
      # max_tokens: 512
    output_parser:
      type: gsm8k

  - #evaluator_agent:
    agent_type: evaluator
    max_retry: 100000
    name: Evaluator
    role_description: |-
      Evaluator
    prompt_template: *evaluator_prompt
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: "gpt-4"
      temperature: 0.3
      # max_tokens: 512
    output_parser:
      type: mgsm-evaluator
      dimensions:
        - Correctness


tools:

